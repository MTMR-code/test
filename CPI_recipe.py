import streamlit as st
import requests
import csv
from io import StringIO
from datetime import datetime
import json
import base64

# Gemini APIã‚­ãƒ¼ã‚’ç©ºæ–‡å­—åˆ—ã«è¨­å®š
API_KEY = "AIzaSyBByzza6IDgyZjHIlvuNgFOHqTU1M_TABI"

# Googleæ¤œç´¢APIã‚’å‘¼ã³å‡ºã™é–¢æ•°
def google_search(query):
    # APIå‘¼ã³å‡ºã—ã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’è¨­å®š
    payload = {
        "queries": [query]
    }
    
    # APIå‘¼ã³å‡ºã—ã®ãŸã‚ã®URLã‚’è¨­å®š
    url = f"https://generativelanguage.googleapis.com/v1beta/models/google_search:search?key={API_KEY}"
    
    # APIå‘¼ã³å‡ºã—ã‚’å®Ÿè¡Œ
    try:
        response = requests.post(url, headers={"Content-Type": "application/json"}, data=json.dumps(payload))
        response.raise_for_status() # ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
        data = response.json()
        
        # æ¤œç´¢çµæœã‚’è§£æã—ã¦æ•´å½¢
        results = []
        for search_result in data.get('results', []):
            for item in search_result.get('results', []):
                results.append({
                    'title': item.get('source_title'),
                    'snippet': item.get('snippet'),
                    'url': item.get('url')
                })
        return results
    except requests.exceptions.RequestException as e:
        st.error(f"Google Search APIã®å‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

@st.cache_data
def load_data(url):
    """
    æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰CSVãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã€‚
    """
    try:
        res = requests.get(url, timeout=10)
        res.encoding = 'shift_jis'
        csv_reader = csv.reader(StringIO(res.text))
        
        header = next(csv_reader)
        
        for _ in range(5):
            next(csv_reader, None)
        
        data = list(csv_reader)
        return header, data
    except requests.exceptions.RequestException as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚URLã‚’ç¢ºèªã™ã‚‹ã‹ã€å†åº¦ãŠè©¦ã—ãã ã•ã„: {e}")
        return None, None

def main():
    st.title('ç‰©ä¾¡ãŒä¸‹è½ã—ã¦ã„ã‚‹é£Ÿæãƒ¬ã‚·ãƒ”ææ¡ˆã‚¢ãƒ—ãƒª ğŸ³')
    st.write("æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°ï¼ˆCPIï¼‰ã®å‰å¹´æ¯”ãŒä¸‹è½ï¼ˆãƒã‚¤ãƒŠã‚¹ï¼‰ã—ã¦ã„ã‚‹é£Ÿæã‚’åŸºã«ã€ãŠå¾—ãªãƒ¬ã‚·ãƒ”ã‚’ææ¡ˆã—ã¾ã™ã€‚")

    url = "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000032103842&fileKind=1"
    
    header, data = load_data(url)
    
    if not data:
        st.stop()
    
    if not data or not data[-1]:
        st.error("ãƒ‡ãƒ¼ã‚¿è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()

    latest_row = data[-1]
    latest_date_str = latest_row[0]

    try:
        latest_date = datetime.strptime(latest_date_str, '%Y%m')
    except (ValueError, IndexError):
        st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®1åˆ—ç›®ã®å¹´æœˆãƒ‡ãƒ¼ã‚¿å½¢å¼ãŒäºˆæœŸã›ã¬å½¢å¼ã§ã™ã€‚ä¾‹: 202301")
        st.stop()

    prev_year_date = latest_date.replace(year=latest_date.year - 1)
    prev_year_date_str = prev_year_date.strftime('%Y%m')
    
    prev_year_row = None
    for row in data:
        if row[0] == prev_year_date_str:
            prev_year_row = row
            break
            
    if prev_year_row is None:
        st.error(f"1å¹´å‰ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ{prev_year_date_str}ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()

    # ã€Œé£Ÿæ–™ã€ã®é–‹å§‹ã¨ã€Œä½å±…ã€ã®é–‹å§‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç‰¹å®š
    food_start_index = -1
    housing_start_index = -1
    for i, col in enumerate(header):
        if col == 'é£Ÿæ–™':
            food_start_index = i
        if col == 'ä½å±…':
            housing_start_index = i
        if food_start_index != -1 and housing_start_index != -1:
            break
            
    if food_start_index == -1:
        st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã«ã€Œé£Ÿæ–™ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()
    
    # å‡¦ç†ç¯„å›²ã‚’ã€Œé£Ÿæ–™ã€ã‹ã‚‰ã€Œä½å±…ã€ã®æ‰‹å‰ã¾ã§ã«é™å®š
    if housing_start_index == -1:
        processing_range = range(food_start_index, len(header))
    else:
        processing_range = range(food_start_index, housing_start_index)

    # ç‰©ä¾¡ä¸‹è½ç‡ã‚’è¨ˆç®—
    calculated_data = []
    for i in processing_range:
        try:
            item = header[i]
            # ã€Œé£Ÿæ–™ã€è‡ªä½“ã®ãƒ‡ãƒ¼ã‚¿ã¯é™¤å¤–
            if item == 'é£Ÿæ–™':
                continue
                
            val_latest = float(latest_row[i])
            val_prev_year = float(prev_year_row[i])
            
            if val_prev_year != 0:
                growth_rate = (val_latest / val_prev_year - 1) * 100
                if growth_rate < 0:
                    calculated_data.append({'å“ç›®': item, 'å‰å¹´æ¯”': f'{growth_rate:.2f}%'})
        except (ValueError, IndexError):
            continue

    if not calculated_data:
        st.info("ç¾åœ¨ã€ç‰©ä¾¡ãŒä¸‹è½ã—ã¦ã„ã‚‹é£Ÿæ–™å“ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()

    falling_foods = sorted(calculated_data, key=lambda x: float(x['å‰å¹´æ¯”'].strip('%')))[:10]

    st.subheader('ç‰©ä¾¡ãŒä¸‹è½ã—ã¦ã„ã‚‹é£Ÿæ–™å“ãƒªã‚¹ãƒˆ')
    st.table(falling_foods)

    selected_food = st.selectbox(
        'ãƒ¬ã‚·ãƒ”ã‚’çŸ¥ã‚ŠãŸã„é£Ÿæã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š',
        [food['å“ç›®'] for food in falling_foods]
    )

    if selected_food:
        st.subheader(f'ã€Œ{selected_food}ã€ã‚’ä½¿ã£ãŸãƒ¬ã‚·ãƒ”æ¤œç´¢çµæœ')
        
        # Googleæ¤œç´¢ã§ãƒ¬ã‚·ãƒ”ã‚’æ¤œç´¢
        search_results = google_search(f"{selected_food} ãƒ¬ã‚·ãƒ”")
        
        if search_results:
            for result in search_results:
                st.markdown(f"**{result['title']}**")
                st.markdown(f"*{result['snippet']}*")
                st.markdown(f"[è©³ç´°ã‚’è¦‹ã‚‹]({result['url']})")
                st.markdown("---")
        else:
            st.info("é¸æŠã•ã‚ŒãŸé£Ÿæã®ãƒ¬ã‚·ãƒ”ã‚’æ¤œç´¢ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

if __name__ == '__main__':
    main()
